# 📚 makemore Part 4: Becoming a Backprop Ninja 笔记

## 🎯 目标

深入理解反向传播（Backprop），通过手动实现MLP的反向传播，掌握梯度计算的细节，提升对神经网络的直觉。

- **Part 3回顾** 🔍: 优化MLP，引入BatchNorm稳定训练，但依赖PyTorch自动求导。
- **Part 4重点** 🌟: 抛开自动求导，手动推导并实现反向传播，强化对梯度流和计算图的理解。

---

## 🧠 代码结构与反向传播流程

### 1️⃣ 前向传播回顾

- **结构**: 嵌入层 → 隐藏层（线性+tanh）→ BatchNorm → 输出层 → 损失（交叉熵）。
- **代码**:
  - 输入：上下文字符索引（batch_size × block_size）。
  - 嵌入：`C[inputs]` → 拼接为输入向量。
  - 隐藏层：`h = W1 @ emb + b1` → `h = tanh(hpreact)`。
  - BatchNorm：标准化`h`（均值0，标准差1，带缩放/偏移）。
  - 输出层：`logits = W2 @ h + b2` → 交叉熵损失。

- **形象化**:

  ```
  输入 → 嵌入 → 隐藏层 → BatchNorm → 输出 → 损失
  ```

- **图标**: 🚀 前向传播像“数据流经网络的旅程”。

### 2️⃣ 反向传播手动实现

- **目标**: 从损失开始，逆向计算每个参数（`W1`, `b1`, `W2`, `b2`, `C`）和中间变量的梯度。

- **代码逻辑**:

  1. **损失梯度**: 交叉熵损失对logits的梯度（`dlogits`）。
  2. **输出层**: `dlogits` → `dW2`, `db2`, `dh`（矩阵乘法和偏置的梯度）。
  3. **BatchNorm**: `dh` → 归一化梯度（考虑均值/方差/缩放）。
  4. **隐藏层**: `dhpreact` → `dW1`, `db1`（考虑tanh导数）。
  5. **嵌入层**: `demb` → `dC`（累加到嵌入表）。

- **关键公式** (以隐藏层为例):

  ```
  h = W1 @ emb + b1
  dW1 = dh @ emb.T  # 权重梯度
  db1 = dh.sum(0)   # 偏置梯度
  demb = W1.T @ dh  # 输入梯度
  ```

- **tanh导数**:

  ```
  h = tanh(hpreact)
  dhpreact = (1 - h^2) * dh  # tanh导数: 1 - tanh(x)^2
  ```

- **形象化**:

  ```
  损失 → 输出层 → BatchNorm → 隐藏层 → 嵌入层 → 参数
  ```

- **图标**: 🔄 反向传播像“梯度逆流回溯”。

### 3️⃣ 验证正确性

- **方法**: 与PyTorch自动求导的梯度比较，确保手动计算的梯度一致。
- **代码**:
  - 计算手动梯度（如`dW1_manual`）。
  - 用`torch.autograd`计算参考梯度（如`W1.grad`）。
  - 检查误差：`torch.allclose(dW1_manual, W1.grad)`。

- **图标**: ✅ 验证像“梯度计算的校对员”。

### 4️⃣ 训练与采样

- **训练**: 用手动梯度更新参数，优化损失。
- **采样**: 与Part 3一致，生成名字。
- **图标**: 🎨 采样像“模型的创意输出”。

---

## 🔑 核心概念

- **计算图** 🕸️: 神经网络的每一步（矩阵乘、激活、损失）组成计算图，反向传播沿图逆向传播梯度。
- **链式法则** 🔗: 梯度通过中间变量逐层传递（如`dL/dW1 = dL/dh * dh/dW1`）。
- **局部梯度** 📍: 每层计算局部导数（如tanh的`1 - h^2`）。
- **梯度累加** 📚: 嵌入表`C`的梯度需累加（多字符共享同一嵌入）。

---

## 🛠️ 实用技巧

- **分解计算** 🧩: 将复杂操作拆分为简单步骤（如矩阵乘 → 逐元素操作）。
- **验证梯度** 🔍: 用小网络或单样本测试，确保手动梯度正确。
- **数值稳定性** ⚖️: 注意除法或大矩阵乘法可能导致数值溢出。
- **调试工具** 🛠️: 打印中间梯度形状，检查是否符合预期。

---

## 📚 资源

- **视频**: Building makemore Part 4: Becoming a Backprop Ninja
- **代码**: nn-zero-to-hero GitHub
- **Colab**: 视频描述中的Jupyter笔记本

---

## 🌟 总结

Part 4通过手动实现MLP的反向传播，深入剖析梯度计算的每一步。理解计算图和链式法则后，能更直观地掌握神经网络的优化过程，手动反向传播强化了对梯度流的洞察。